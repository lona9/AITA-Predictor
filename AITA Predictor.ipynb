{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf773e26",
   "metadata": {},
   "source": [
    "# Am I The A-hole Predictor Project\n",
    "\n",
    "## Table of contents\n",
    "- <a href=\"#intro\">Introduction</a>\n",
    "- <a href=\"#loading\">Loading and assessment</a>\n",
    "- <a href=\"#cleaning\">Cleaning</a>\n",
    "- <a href=\"#overview\">General Overview</a>\n",
    "- <a href=\"#insights\">Insights</a>\n",
    "- <a href=\"#tester\">Predictions Tester</a>\n",
    "- <a href=\"#discussion\">Discussion</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dd2502",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "## Introduction\n",
    "This project is based on one of Reddit's most popular section: <a href=\"https://www.reddit.com/r/AmItheAsshole/\">r/AmITheAsshole</a>. This subreddit (AITA for short) has a simple premise of having people post about social experiences where they're unsure if they're the one at fault or not. Redditors participate in deciding their judgement, commenting on the situation, giving a brief summary of what they think is going on and argumenting for each of the valid judgements:\n",
    "\n",
    "- **YTA** (You're the A-hole)\n",
    "- **NTA** (Not the A-hole, but the other person is)\n",
    "- **ESH** (Everyone Sucks Here)\n",
    "- **NAH** (No A-holes Here)\n",
    "\n",
    "People vote in their comments, and after 18 hours, a flair is given to each post with the verdict of the public, which then usually translates to the original posters reacting to their judgement, for better or worse (and this is where this subreddit gets one of the juiciest comment sections on the entire website!). However, this being both Reddit and the internet, there are some biases included, and the crowd allegedly tends to pick certain verdicts when the story has some buzzwords or characters which are not as favored in the internet, such as: mothers-in-law, pregnant people, childen being loud, among many others, as well as certain situations where the subreddit is pretty vocal about defending, specially when it includes people asking for help when there's no legal obligation to do so.\n",
    "\n",
    "In this project, I took this perceived notion of being able to predict the outcome when the story is told in a certain way or with certain participates, and retrieved a dataset of 150,000 submissions, processed to obtain some descriptive statistics about posts based on Reddit activity such as comments and up/downvotes to characterize the posts and see if the usually talked about patterns are actually there or not, and build a machine learning model to predict the verdict of a user input text telling a story."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9ebe83",
   "metadata": {},
   "source": [
    "**Import statements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c640e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import classification_report\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a6b69c",
   "metadata": {},
   "source": [
    "<a id=\"loading\"></a>\n",
    "## Loading and assessment\n",
    "\n",
    "The dataset was obtained from a script which uses two Reddit APIs to obtain posts and then pull information about each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(\"reddit_scraper/reddit_posts.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad584a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7a8f97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02c1ae3",
   "metadata": {},
   "source": [
    "The fields available were decided based on the <a href=\"https://praw.readthedocs.io/en/latest/code_overview/models/submission.html?highlight=submission\">PRAW docs</a> for both the ML model and analytics:\n",
    "- **title**: title of the submission\n",
    "- **id**: ID of the submission\n",
    "- **score**: The number of upvotes for the submission.\n",
    "- **upvote_ratio**: The percentage of upvotes from all votes on the submission.\n",
    "- **url**: The URL the submission links to, or the permalink if a selfpost.\n",
    "- **num_comments**: The number of comments on the submission.\n",
    "- **body (renamed from selftext)**: The submissions’ selftext - an empty string if a link post. \n",
    "- **created**: Time the submission was created, represented in Unix Time.\n",
    "- **edited**: Whether or not the submission has been edited.\n",
    "- **verdict** (renamed from link_flair_text): The link flair’s text content, or None if not flaired.\n",
    "- **over_18**: Whether or not the submission has been marked as NSFW.\n",
    "\n",
    "The main fields for the model are the content body of the submission and the verdict, which comes from the submission flair, which is given after the 18 hours of people commenting on the post."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112c03f7",
   "metadata": {},
   "source": [
    "<a id=\"cleaning\"></a>\n",
    "## Cleaning\n",
    "\n",
    "For the analysis, we will remove posts with tags outside the verdicts (mod posts or without a flair). Also, \"Not enough info\" posts will be removed as well, as they're considered invalid from the submission point of view.\n",
    "\n",
    "The edited column has a mix of datatypes, so we'll change it to a boolean type to know if the post was edited or not.\n",
    "\n",
    "After cleaning, over 75% of the posts were removed, so the clean dataframe has around valid 35k posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d56c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.verdict.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3390d5ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nan = np.nan\n",
    "clean_df = df.query(\"verdict not in ['TL;DR', 'UPDATE', @nan, 'Talk ENDED', 'Open Forum', 'Mods Needed!', 'META', 'Not enough info']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1781f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_edited = []\n",
    "\n",
    "for i in clean_df.edited.values:\n",
    "    if i == 'False':\n",
    "        column_value = False\n",
    "    else:\n",
    "        column_value = True\n",
    "    is_edited.append(column_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53630fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.insert(8, 'is_edited', is_edited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ae7e24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_df = clean_df.drop(columns=[\"edited\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d8cbd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_df.created = pd.to_datetime(clean_df.created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4378d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.insert(8, 'isoweek', clean_df.created.dt.isocalendar().week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f2f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.insert(8, 'hour_of_day', clean_df.created.dt.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8b7a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf74ec6",
   "metadata": {},
   "source": [
    "<a id=\"overview\"></a>\n",
    "## General overview\n",
    "\n",
    "We start by getting a general overview of the valid posts, which were defined as having a verdict flair and a body that wasn't removed or deleted. The dataset is unbalanced, as it has a lot more submissions where the verdict was **NTA** over all the other verdicts. This already gives us indication that people tend to post more stories where they wouldn't be deemed the A-holes (a popular theory in the subreddit) and/or that people tend to validate people in their actions, which could also be the case since they're posting one-sided stories where they could always hide inconvenient facts.\n",
    "\n",
    "The timeframe for the data is from mid-August to end of year, 2021, which covers some major holidays, so we could take a closer look at holiday-related posts and see if there's an increase during these days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b34543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_df.verdict.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8c65fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_df.sort_values(by=\"created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c90464e",
   "metadata": {},
   "source": [
    "<a id=\"insights\"></a>\n",
    "## Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaeb394",
   "metadata": {},
   "source": [
    "As previously noted, most of the posts have a **NTA** verdict, and account for nearly 75% of the cleaned dataset. We'll explore the distribution of different attributes grouped by verdict to see if we can find some additional insights as to how people behave when interacting with this subreddict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2bf689",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_posts = clean_df.id.count()\n",
    "pctg_verdicts = clean_df.verdict.value_counts() / total_posts * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19e326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## general parameters for plotting\n",
    "legends = list(clean_df.verdict.unique().astype(\"str\"))\n",
    "ind = np.arange(len(pctg_verdicts))\n",
    "ticks = np.arange(len(legends))\n",
    "width = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6617f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting\n",
    "plt.figure(figsize=(8,5.5), dpi=100)\n",
    "plt.bar(ind, pctg_verdicts, width, label = \"Percentage of posts\", color=(0.33, 0.62, 0.67, 0.85))\n",
    "\n",
    "plt.ylabel('Percentage of posts', fontsize=14)\n",
    "plt.xlabel('Verdicts', fontsize=14)\n",
    "plt.title('Proportion of verdicts', fontsize=20)\n",
    "locations = ticks\n",
    "plt.xticks(locations, legends, fontsize=12)\n",
    "plt.yticks()\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79699c3",
   "metadata": {},
   "source": [
    "### Removed and deleted posts proportion\n",
    "\n",
    "A very usual concern when posting is being found by people you know on Reddit, or sometimes you post something and get hit with the overwhelming feel of shame that you want to delete your existence off the internet (though if it's on the Internet, it'll stay there forever!), so you try to at least clear your Reddit traces. Sometimes, your content doesn't fulfill subreddit standards and mods delete your post, to avoid clutter. There might be a few reasons, but the reality is that a lot of posts get removed by users or mods, so we tried to take a closer look at this missing posts, using both the original dataframe. \n",
    "\n",
    "When checking, we find over 100k posts (which were removed from the original dataset for other analysis) which don't have neither a flair or body. The removed body posts are invalid submissions cleaned by mods or automods. The deleted submissions represents those removed by the original poster, which are a much less in comparison.\n",
    "\n",
    "The proportions of deleted posts are similar for all verdicts and slightly higher for the more positive verdicts, so apparently people who are deemed A-holes by Redditors are not into removing their content after all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc278f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"verdict.isnull() & body in ['[removed]', '[deleted]']\",engine='python').body.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b1710d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_posts = clean_df.verdict.value_counts()\n",
    "deleted_posts = clean_df.query(\"body == '[deleted]'\").verdict.value_counts()\n",
    "total_posts / deleted_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fa5ab0",
   "metadata": {},
   "source": [
    "### Time distribution of posts\n",
    "\n",
    "When looking at distribution of valid posts based on when they were posted, we some clear find some patterns. First, the distribution based on hour of day (UTC) reached its peak during afternoon hours, and slowly decreases until its lowest point at 6AM. Even when considering timezones, we can see that people are posting a lot more during school/work hours rather than nighttime, which could have been expected if we consider the typical night-owl stereotype. \n",
    "\n",
    "For week distribution, the time range considered is from late August to end of year, so we'd cover Thanksgiving (ISO Week 47) and Christmas (ISO Week 51), which are indeed the busiest weeks in our range, and matches with the usual background stories for AITA posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f064128",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hour_distribution = clean_df.groupby('hour_of_day').id.count().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1fa3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## general parameters for plotting\n",
    "legends = clean_df.groupby('hour_of_day').id.count().index\n",
    "ind = np.arange(len(hour_distribution))\n",
    "ticks = np.arange(len(legends))\n",
    "width = 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703775a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting\n",
    "plt.figure(figsize=(10,5.5), dpi=100)\n",
    "plt.bar(ind, hour_distribution, width, label = \"Percentage of posts\", color=(0.33, 0.62, 0.67, 0.85))\n",
    "\n",
    "plt.ylabel('Amount of valid posts', fontsize=14)\n",
    "plt.xlabel('Hour of day', fontsize=14)\n",
    "plt.title('Hour of Day Distribution', fontsize=20)\n",
    "locations = ticks\n",
    "plt.xticks(locations, legends, fontsize=12)\n",
    "plt.yticks()\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f9d0d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "week_distribution = clean_df.groupby('isoweek').id.count().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba9c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "## general parameters for plotting\n",
    "legends = clean_df.groupby('isoweek').id.count().index\n",
    "ind = np.arange(len(week_distribution))\n",
    "ticks = np.arange(len(legends))\n",
    "width = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33aa09c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## plotting\n",
    "plt.figure(figsize=(10,5.5), dpi=100)\n",
    "plt.bar(ind, week_distribution, width, label = \"Percentage of posts\", color=(0.33, 0.62, 0.67, 0.85))\n",
    "\n",
    "plt.ylabel('Amount of valid posts', fontsize=14)\n",
    "plt.xlabel('ISO Week', fontsize=14)\n",
    "plt.title('ISO Week Distribution', fontsize=20)\n",
    "locations = ticks\n",
    "plt.xticks(locations, legends, fontsize=12)\n",
    "plt.yticks()\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bc0ecf",
   "metadata": {},
   "source": [
    "### Number of comments and upvotes\n",
    "\n",
    "When looking at descriptive statistics of the numerical fields, we can see that, in average, posts with YTA and ESH verdicts have higher number of comments than NTA and NAH, which could be due to people wanting to voice their opinions more on situations where you want to tell the OPs they're wrong, or because longer discussions start in the comment sections. On a similar note, the scores and upvote ratios are lower in YTA than the rest of the verdicts, which is also related to the previous point, as people will downvote posts where people are being AHs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6354c4a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_df.groupby(\"verdict\").describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dff7d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_comments = clean_df.groupby(\"verdict\").num_comments.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ee048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## general parameters for plotting\n",
    "legends = upvote_ratio.index\n",
    "ind = np.arange(len(upvote_ratio))\n",
    "ticks = np.arange(len(legends))\n",
    "width = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e4d7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## plotting\n",
    "plt.figure(figsize=(10,5.5), dpi=100)\n",
    "plt.bar(ind, num_comments, width, label = \"Comments\", color=(0.33, 0.62, 0.67, 0.85))\n",
    "\n",
    "plt.ylabel('Average comments', fontsize=14)\n",
    "plt.xlabel('Verdict', fontsize=14)\n",
    "plt.title('Average comments per post', fontsize=20)\n",
    "locations = ticks\n",
    "plt.xticks(locations, legends, fontsize=12)\n",
    "plt.yticks()\n",
    "sns.despine();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea583c7",
   "metadata": {},
   "source": [
    "### Word Clouds\n",
    "\n",
    "As an extra, and to compare the most used words in our two opposite sides: YTA and NTA verdicts, we'll create some word clouds images for both classes, and see what we can find. First, we'll create the files necessary for the script, running the following cells, and then we can run the script from the main folder, running `python wordclouds/wordcloud_builder.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2895f53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nta_df = clean_df.query(\"verdict == 'Not the A-hole'\").sort_values(by=\"num_comments\", ascending=False).head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7445ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "yta_df = clean_df.query(\"verdict == 'Asshole'\").sort_values(by=\"num_comments\", ascending=False).head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414609a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nta_text = []\n",
    "\n",
    "for text in nta_df.body.values:\n",
    "    with open(os.path.join(\"wordclouds/nta_text.txt\"), \"a+\") as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74ac570",
   "metadata": {},
   "outputs": [],
   "source": [
    "yta_text = []\n",
    "\n",
    "for text in yta_df.body.values:\n",
    "    with open(os.path.join(\"wordclouds/yta_text.txt\"), \"a+\") as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6365df66",
   "metadata": {},
   "source": [
    "<a id=\"tester\"></a>\n",
    "## Predictions Tester"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c9934",
   "metadata": {},
   "source": [
    "After building our model in previous steps (see instructions on this repo's README file), we can test how it works with some real life examples. Recent posts were taken from Reddit and used as test for each of the verdicts. The predictions were NTA for 3/4 cases (including the NTA test), and the ESH test ended as **YTA**, which was the only one classified as deeming the OP as an A-hole. \n",
    "\n",
    "You can also test your own story if you want to at the end of this section!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50a9393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    urls = \"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
    "    detected_urls = re.findall(urls, text)\n",
    "\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    words = [x for x in words if x not in stop_words]\n",
    "\n",
    "    clean_tokens = []\n",
    "    for word in words:\n",
    "        clean_token = lemmatizer.lemmatize(word).strip().lower()\n",
    "        clean_tokens.append(clean_token)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9493ed79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = joblib.load(\"model/model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796da660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nta\n",
    "nta_test = \"I dont even know where to begin. My kids (9m, 9f, 6m) hardly ever see their dad or his family. He stopped taking the kids randomly back in 2017 and after that point, the kids grandmother would randomly take them but it was incredibly sporadic. Like once every 6 months or so. When she would take them, they would see their dad and most of the family- because usually their grandmother only took them during holiday. I was very lenient with this. The kids wanted to go and I wasnt about to tell them no, despite me missing every single holiday with my kids since 2017 because of this schedule. But this is a selfish thought on my end anyways so I overlooked it. The kids had fun. That's all that matters.So as of recently I noticed that their grandmother and even their dad started taking them more. Initially I assumed it was because their dad finally came to his senses but apparently that's not the case. But regardless, like once every couple of months the kids have been going there. Well, their grandmother got ahold of me about 3 weeks ago and told me that my children's grandfather had a heart attack and needed surgery but assured me he was fine. If he hadnt been, I would have 100% told the kids myself. A few days later, the grandmother posted a video on TikTok stating she had been diagnosed with Alplacia and then on Thursday I'm told that the kids great grandfather had been diagnosed with stage 4 lung cancer. I didnt tell my kids about any of it. I had plenty of reasons not to. One being the fact that the kids were going over soon so I figured it be best that they be the ones to break the news and two being that I knew my kids would completely panic and start freaking out and ask to go see them right then and there- which would have been denied by the grandparents due to them having a busy schedule. So I just didnt say anything.Well, my kids go over there last weekend and when they get dropped off, their grandmother asks me why I hadnt told them what was going on and stated that it ''took away from their time' with the kids because they had to explain everything, which led to my kids panicking and asking questions all weekend versus have a good time. She said I should have told them and the fact that I didnt really ruined their weekend. AITA?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nah_test = \"Today is my birthday!My family and I don’t see each other a lot so usually birthdays are when we all come together. I haven’t heard from my Mom or grandma at all until last Saturday.My grandma asked me what I wanted to do and I told her I didn’t know if anyone wanted to do anything because nobody had said anything. She then told me I should’ve said something sooner because they were waiting on me.That took me by surprise because on Facebook, I always see them eating together with my uncle who lives out of town. I never get invited and I should probably speak up about my feelings but haven’t yet. I just feel like they’re trying to pick fights with me because other than them, my friends, other grandma and even my fiancés family have asked me what my plans are and we’ve already celebrated.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd24176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yta_test = \"Using my alt account.Last Friday, I (25M) was killing time at work with my friend “Cap” (24M). We have one of those big industrial scanners, and he suggested me to scan my ass and see what happens. I agreed to try, and I balanced on a chair to put my ass on the machine. It didn’t work, so Cap told me to pull down my pants and boxers.Just as this was happening, my team leader “Sarah” (30?F) came into the print room. She just walked out without a word, but I heard from Cap that she is accusing me of making work into a sexual environment. I spoke to her kindly and told her it wasn’t a lood thing and was only a joke.Now, she’s blowing up our team Skype with all kinds of allegations about me, including that I have a serious disease. Not sure if I can name it here, but I’m sure you can guess. I’m going to HR tomorrow about her, but AITA for goofing around with my friend in the first place?\"\n",
    "yta_test = \"I (30f) have a younger brother Michael (24m) who got an apartment with his girlfriend (22f) of 5yrs a year ago. I went to visit and before I even walked in I could hear her barking orders at him to clean this, do that, etc. After I came in and we all sat down I asked what was all that I heard. They both looked at me confused and I explained I heard her saying all that stuff to him. She laughed out off saying 'oh that's because Micheal won't do anything unless I act like his mother.' I was taken back by her casually putting down my brother like that . After we ate and she went to wash dishes I pulled him to aside to ask why he just accepted the way she treats him. At first he tried to make excuses saying 'she is just a traditional girl and she likes them having set roles and jobs in the household.' I told him 'that is bs and this is 2022 relationships are supposed to be 50/50 or nothing at all.' I also told him it wasn't okay for her to be jobless and just staying home all day is childish and they need to have a major talk.' I know he took my words to heart because a few days later I found out from my younger sister they got into multiple heated arguments for few days after then she left.Weeks later I thought everything was said and done till I got an angry call from my mom telling me to fix what I ruined and to go back to my brother's place. I went over there oh dear Lord the smell as soon as you open the door is awful. It was a mix of dirty dishes mixed with clothes on the floor and furniture, dried up sticky marks on the carpet and tiles from stuff spilled and left there, and trash piled up near the full trash can. He didn't even react to me seeing all of this and just sat back down kept playing his game. I asked him how has he been since she left and he claims he is fine except for shopping and cooking meals. I talked with him a little bit more and he seemed fine. I left and then called my mother to say 'he was fine. A complete slob but fine.' She yelled at me saying how 'I shouldn't have gotten involved because now he has nobody to take care of him and he doesn't have the drive to do it himself outside of basic needs.' I told her 'it's not my fault she failed as mom to teach him how to take care of himself and he is grown man he gets to decide how he wants to live.' I hung up and I've been receiving calls and texts from her and a few other family members saying how I shouldn't have interfered. Yesterday my fiance told me his friend who also lives in the same apartment complex talked to the landlord and he is thinking about kicking him out due to the indecent smell coming from his place (he hasn't seen the inside) and he isn't allowed to stay with us if he gets kicked.Edit: to clarify she comes from a traditional family so she was planning to be SAHM/SAHW so she was okay with him with till he asked her for 50/50 and she gets a job too.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed0602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "esh_test = \"During the middle of February, my girlfriend (20F) ended things with me (21M). We kept hanging out every day because I was one of her only friends and she still wanted a friendship.I was pretty pissed when it happened and texted my friends “Eff gf for life.” I also kissed 2 people a couple days after she ended things. The last thing I did was talk about how hot other girls were, one of the girls was her friend.My gf also kissed another guy 2.5 weeks after it happened. She was planning on sleeping with him but they never got the chance before I found out. I was pretty pissed but let it go after I found out they hadn’t slept together because I had done the same and didn’t tell her either and we were broken up.My buddy’s gf went on his phone and found the texts talking about making out with other girls, calling other girls hot, and venting about my gf to my best friend. She sent my gf screenshots of the texts and ever since then she has been furious with me. She says I betrayed her on a Relationship level and friendship level. Am I the asshole for making out with girls and ranting about my gf after she ended things. I know it was mean to talk poorly about her but I know she has done the same. Reddit what do you think?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f356721",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The prediction for the NTA test is: {model.predict([nta_test])[0]}\")\n",
    "print(f\"The prediction for the NAH test is: {model.predict([nah_test])[0]}\")\n",
    "print(f\"The prediction for the YTA test is: {model.predict([yta_test])[0]}\")\n",
    "print(f\"The prediction for the ESH test is: {model.predict([esh_test])[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbe6837",
   "metadata": {},
   "source": [
    "You can try your own story, running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef4c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_story = \"\" ## write your story here\n",
    "\n",
    "print(f\"The prediction for your story is: {model.predict([your_story])[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd38ee8",
   "metadata": {},
   "source": [
    "<a id=\"discussion\"></a>\n",
    "## Discussion\n",
    "\n",
    "This project represents the end of the Nanodegree, and was created from scratch thinking of something that could be both fun and could provide insight from a popular website that I personally browse everyday. It was challenging, and tries to cover a little bit of everything learned through this course. \n",
    "\n",
    "The dataset was obtained from scratch using Reddit APIs, which was a whole world to explore on its own and took a lot of testing to get the information with the desired format and using the right filters. Thanks to this, the dataset required minimal cleaning steps, mostly for formatting issues, as it was designed and then retrieved from the API with the project in mind. This process required some iteration regarding the size of the dataset, because over 3/4 of the original posts were removed as they had an invalid or null flair, so the script was modified until a better sample size was gathered for the smaller classes.\n",
    "\n",
    "The machine learning pipeline was similar to what was covered during the course, but proved to be even more rewarding when using original data and iterating through the script to improve its metrics for a better model. The original dataset was biased towards a particular verdict, so several things were tested before the final version which improved its metrics from the first one. A few things were implemented, like accounting for imbalaced classes with the `class_weight` parameter, trying different dataset sizes, trying two classifiers (AdaBoostClassifier and RandomForestClassifier) and looking through different parameters to test with GridSearch. The final F-score considering all implementations reached 0.6, which improved from the previous trials (AdaBoostClassifier gave the lowest F-score of all tests). This metric was selected as the best one to measure model performance, as we were dealing with unbalanced classes. It's not perfect (yet), due to the complexity of this challenge, which might be a bit ambitious in wanting to classify based on internet users' moral compass, which is an issue on its own.\n",
    "\n",
    "As for analytical results, we were able to visualize a few different trends regarding behaviour around these posts, like the comment activity and willingness to delete your own posts based on verdicts. We also saw some pattern when it comes to distribution of posts for hours of day and ISO weeks. The word clouds bring us insight about the most common words between two opposite verdicts, and might be interesting to analyze when it comes to the popular topics talked about in these two classes.\n",
    "\n",
    "This project helped consolidate the notions of how to approach a data science problem with a real-life example, with data obtained from scratch and processed entirely for this purpose, and build a model that could turn into something fun to use, as well as learn the difficulties when working with text data and trying to interpret moral decisiones based on words. As for things which could be further improved, a larger dataset could be retrieved to get more examples of the smaller classes, and try additional NLP algorithms for text analysis. A web app could be built with the model in the backend, to directly give a story as an input and receive a prediction instead of using this notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
