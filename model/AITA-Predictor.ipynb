{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf773e26",
   "metadata": {},
   "source": [
    "# Am I The A-hole Predictor Project\n",
    "\n",
    "This project is based on one of Reddit's most popular section: <a href=\"https://www.reddit.com/r/AmItheAsshole/\">r/AmITheAsshole</a>. This subreddit (AITA for short) has a simple premise of having people post about social experiences where they're unsure if they're the one at fault or not. Redditors participate in deciding their judgement, commenting on the situation, giving a brief summary of what they think is going on and argumenting for each of the valid judgements:\n",
    "\n",
    "- **YTA** (You're the A-hole)\n",
    "- **NTA** (Not the A-hole, but the other person is)\n",
    "- **ESH** (Everyone Sucks Here)\n",
    "- **NAH** (No A-holes Here)\n",
    "- **INFO** (Not enough information)\n",
    "\n",
    "People vote in their comments, and after 18 hours, a flair is given to each post with the verdict of the public, which then usually translates to the original posters reacting to their judgement, for better or worse (and this is where this subreddit gets one of the juiciest comment sections on the entire website!). However, this being both Reddit and the internet, there are some biases included, and the crowd allegedly tends to pick certain verdicts when the story has some buzzwords or characters which are not as favored in the internet, such as: mothers-in-law, pregnant people, childen being loud, among many others, as well as certain situations where the subreddit is pretty vocal about defending, specially when it includes people asking for help when there's no legal obligation to do so.\n",
    "\n",
    "In this project, I took this perceived notion of being able to predict the outcome when the story is told in a certain way or with certain participates, and a dataset of 100,000 submissions was obtained and processed to obtain some descriptive statistics about posts based on Reddit activity such as comments and up/downvotes to characterize the posts, and build a machine learning model to predict the verdict of a user input text telling a story."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9ebe83",
   "metadata": {},
   "source": [
    "**Import statements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2c640e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a6b69c",
   "metadata": {},
   "source": [
    "**Loading the dataset**\n",
    "\n",
    "The dataset was obtained from a script which uses two Reddit APIs to obtain posts and then pull information about each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "279b3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/pilarvasquez/Documents/Repos/AITA-Predictor/reddit_scraper/reddit_posts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112c03f7",
   "metadata": {},
   "source": [
    "**Cleaning up rows**\n",
    "\n",
    "Remove from dataset all rows without a body, and rows with tags outside the verdicts (mod posts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3390d5ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nan = np.nan\n",
    "clean_df = df.query(\"body not in ['[deleted]', '[removed]'] & verdict not in ['TL;DR', 'UPDATE', @nan, 'Talk ENDED', 'Open Forum', 'Mods Needed!', 'META']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ace260c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>body</th>\n",
       "      <th>created</th>\n",
       "      <th>edited</th>\n",
       "      <th>verdict</th>\n",
       "      <th>over_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>AITA for giving my MIL a fake copy of my house...</td>\n",
       "      <td>rrjhmz</td>\n",
       "      <td>41057</td>\n",
       "      <td>0.97</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>4983</td>\n",
       "      <td>\\nI wanna preface this by saying that I f34 ma...</td>\n",
       "      <td>2021-12-29 18:38:13</td>\n",
       "      <td>1640821313.0</td>\n",
       "      <td>Not the A-hole</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65632</th>\n",
       "      <td>AITA for kicking out my girlfriend</td>\n",
       "      <td>qkntpa</td>\n",
       "      <td>35463</td>\n",
       "      <td>0.97</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>1946</td>\n",
       "      <td>So I have a cat named Raven who's 3 years old....</td>\n",
       "      <td>2021-11-01 18:06:27</td>\n",
       "      <td>False</td>\n",
       "      <td>Not the A-hole</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>AITA for setting a glitter trap to catch my mo...</td>\n",
       "      <td>rsnfcq</td>\n",
       "      <td>34346</td>\n",
       "      <td>0.98</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>2607</td>\n",
       "      <td>For some weird reason my MIL really wants to g...</td>\n",
       "      <td>2021-12-31 03:27:13</td>\n",
       "      <td>1640981534.0</td>\n",
       "      <td>Not the A-hole</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16904</th>\n",
       "      <td>AITA for telling my fianc√© if I see her friend...</td>\n",
       "      <td>rijyk1</td>\n",
       "      <td>33318</td>\n",
       "      <td>0.97</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>2796</td>\n",
       "      <td>Edit: Update. I want to thank you all for the ...</td>\n",
       "      <td>2021-12-17 12:33:20</td>\n",
       "      <td>1639778419.0</td>\n",
       "      <td>Not the A-hole</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70815</th>\n",
       "      <td>AITA for losing weight before my sister's wedd...</td>\n",
       "      <td>qgxbzw</td>\n",
       "      <td>33096</td>\n",
       "      <td>0.94</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>3692</td>\n",
       "      <td>I 28F used to be quite overweight, over the la...</td>\n",
       "      <td>2021-10-27 11:00:03</td>\n",
       "      <td>False</td>\n",
       "      <td>Not the A-hole</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71299</th>\n",
       "      <td>AITA for making a classmate leave the class be...</td>\n",
       "      <td>qgk973</td>\n",
       "      <td>0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>57</td>\n",
       "      <td>I  was in class today, in the university caree...</td>\n",
       "      <td>2021-10-26 21:27:42</td>\n",
       "      <td>1635298606.0</td>\n",
       "      <td>Asshole</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33707</th>\n",
       "      <td>AITA Friends ghost me after one claims I said ...</td>\n",
       "      <td>r6xr83</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>9</td>\n",
       "      <td>So for reference I used to be a member of this...</td>\n",
       "      <td>2021-12-02 00:37:21</td>\n",
       "      <td>False</td>\n",
       "      <td>Everyone Sucks</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7722</th>\n",
       "      <td>AITA for demanding quarantine because of a sto...</td>\n",
       "      <td>rogo42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>15</td>\n",
       "      <td>So, my BIL is in therapy and assisted living (...</td>\n",
       "      <td>2021-12-25 17:20:21</td>\n",
       "      <td>False</td>\n",
       "      <td>Not the A-hole</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79987</th>\n",
       "      <td>AITA for deciding to cut a friend off after ge...</td>\n",
       "      <td>qbfrox</td>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>8</td>\n",
       "      <td>I (16F) have been friends with ‚ÄúZee‚Äù (16F) for...</td>\n",
       "      <td>2021-10-19 13:59:35</td>\n",
       "      <td>False</td>\n",
       "      <td>Not the A-hole</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43590</th>\n",
       "      <td>AITA for shouting at my parents in an argument...</td>\n",
       "      <td>r07r2m</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>5</td>\n",
       "      <td>Context: I(14 M) have diagnosed ADHD and strug...</td>\n",
       "      <td>2021-11-23 04:26:14</td>\n",
       "      <td>False</td>\n",
       "      <td>Not the A-hole</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21852 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title      id  score  \\\n",
       "2637   AITA for giving my MIL a fake copy of my house...  rrjhmz  41057   \n",
       "65632                 AITA for kicking out my girlfriend  qkntpa  35463   \n",
       "920    AITA for setting a glitter trap to catch my mo...  rsnfcq  34346   \n",
       "16904  AITA for telling my fianc√© if I see her friend...  rijyk1  33318   \n",
       "70815  AITA for losing weight before my sister's wedd...  qgxbzw  33096   \n",
       "...                                                  ...     ...    ...   \n",
       "71299  AITA for making a classmate leave the class be...  qgk973      0   \n",
       "33707  AITA Friends ghost me after one claims I said ...  r6xr83      0   \n",
       "7722   AITA for demanding quarantine because of a sto...  rogo42      0   \n",
       "79987  AITA for deciding to cut a friend off after ge...  qbfrox      0   \n",
       "43590  AITA for shouting at my parents in an argument...  r07r2m      0   \n",
       "\n",
       "       upvote_ratio                                                url  \\\n",
       "2637           0.97  https://www.reddit.com/r/AmItheAsshole/comment...   \n",
       "65632          0.97  https://www.reddit.com/r/AmItheAsshole/comment...   \n",
       "920            0.98  https://www.reddit.com/r/AmItheAsshole/comment...   \n",
       "16904          0.97  https://www.reddit.com/r/AmItheAsshole/comment...   \n",
       "70815          0.94  https://www.reddit.com/r/AmItheAsshole/comment...   \n",
       "...             ...                                                ...   \n",
       "71299          0.40  https://www.reddit.com/r/AmItheAsshole/comment...   \n",
       "33707          0.45  https://www.reddit.com/r/AmItheAsshole/comment...   \n",
       "7722           0.50  https://www.reddit.com/r/AmItheAsshole/comment...   \n",
       "79987          0.38  https://www.reddit.com/r/AmItheAsshole/comment...   \n",
       "43590          0.50  https://www.reddit.com/r/AmItheAsshole/comment...   \n",
       "\n",
       "       num_comments                                               body  \\\n",
       "2637           4983  \\nI wanna preface this by saying that I f34 ma...   \n",
       "65632          1946  So I have a cat named Raven who's 3 years old....   \n",
       "920            2607  For some weird reason my MIL really wants to g...   \n",
       "16904          2796  Edit: Update. I want to thank you all for the ...   \n",
       "70815          3692  I 28F used to be quite overweight, over the la...   \n",
       "...             ...                                                ...   \n",
       "71299            57  I  was in class today, in the university caree...   \n",
       "33707             9  So for reference I used to be a member of this...   \n",
       "7722             15  So, my BIL is in therapy and assisted living (...   \n",
       "79987             8  I (16F) have been friends with ‚ÄúZee‚Äù (16F) for...   \n",
       "43590             5  Context: I(14 M) have diagnosed ADHD and strug...   \n",
       "\n",
       "                   created        edited         verdict  over_18  \n",
       "2637   2021-12-29 18:38:13  1640821313.0  Not the A-hole    False  \n",
       "65632  2021-11-01 18:06:27         False  Not the A-hole    False  \n",
       "920    2021-12-31 03:27:13  1640981534.0  Not the A-hole    False  \n",
       "16904  2021-12-17 12:33:20  1639778419.0  Not the A-hole    False  \n",
       "70815  2021-10-27 11:00:03         False  Not the A-hole    False  \n",
       "...                    ...           ...             ...      ...  \n",
       "71299  2021-10-26 21:27:42  1635298606.0         Asshole    False  \n",
       "33707  2021-12-02 00:37:21         False  Everyone Sucks    False  \n",
       "7722   2021-12-25 17:20:21         False  Not the A-hole    False  \n",
       "79987  2021-10-19 13:59:35         False  Not the A-hole    False  \n",
       "43590  2021-11-23 04:26:14         False  Not the A-hole    False  \n",
       "\n",
       "[21852 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.sort_values(by=\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffb8626e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21852"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7173fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_edited = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d867cd99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9089"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.body.str.contains(\"mil\", case=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce93f2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.body.str.contains(\"mother-in-law\", case=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a08a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.body.str.contains(\"mil|mother-in-law|mother in law\", case=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6d3c186",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99965    2021-09-30 14:32:00\n",
       "99968    2021-09-30 14:23:56\n",
       "99970    2021-09-30 14:23:32\n",
       "99973    2021-09-30 14:21:24\n",
       "99982    2021-09-30 14:13:03\n",
       "99983    2021-09-30 14:12:06\n",
       "99989    2021-09-30 14:07:20\n",
       "99990    2021-09-30 14:07:12\n",
       "99992    2021-09-30 14:05:17\n",
       "99997    2021-09-30 14:03:03\n",
       "Name: created, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.created.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ac4336a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21852 entries, 1 to 99997\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   title         21852 non-null  object \n",
      " 1   id            21852 non-null  object \n",
      " 2   score         21852 non-null  int64  \n",
      " 3   upvote_ratio  21852 non-null  float64\n",
      " 4   url           21852 non-null  object \n",
      " 5   num_comments  21852 non-null  int64  \n",
      " 6   body          21852 non-null  object \n",
      " 7   created       21852 non-null  object \n",
      " 8   edited        21852 non-null  object \n",
      " 9   verdict       21852 non-null  object \n",
      " 10  over_18       21852 non-null  bool   \n",
      "dtypes: bool(1), float64(1), int64(2), object(7)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d016cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21852.000000</td>\n",
       "      <td>21852.000000</td>\n",
       "      <td>21852.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>608.442889</td>\n",
       "      <td>0.799142</td>\n",
       "      <td>117.842577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2274.651992</td>\n",
       "      <td>0.141629</td>\n",
       "      <td>370.333993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41057.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8053.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score  upvote_ratio  num_comments\n",
       "count  21852.000000  21852.000000  21852.000000\n",
       "mean     608.442889      0.799142    117.842577\n",
       "std     2274.651992      0.141629    370.333993\n",
       "min        0.000000      0.110000      3.000000\n",
       "25%        6.000000      0.710000     16.000000\n",
       "50%       16.000000      0.820000     28.000000\n",
       "75%       96.000000      0.920000     61.000000\n",
       "max    41057.000000      1.000000   8053.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52b9e2c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not the A-hole     16211\n",
       "Asshole             3068\n",
       "No A-holes here     1222\n",
       "Everyone Sucks       876\n",
       "Not enough info      475\n",
       "Name: verdict, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.verdict.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "208df58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verdict\n",
       "Asshole            0.699498\n",
       "Everyone Sucks     0.745308\n",
       "No A-holes here    0.759542\n",
       "Not enough info    0.723242\n",
       "Not the A-hole     0.826118\n",
       "Name: upvote_ratio, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.groupby(\"verdict\").upvote_ratio.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12dff7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verdict\n",
       "Asshole            193.902868\n",
       "Everyone Sucks     110.381279\n",
       "No A-holes here     59.662848\n",
       "Not enough info     82.488421\n",
       "Not the A-hole     109.272593\n",
       "Name: num_comments, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.groupby(\"verdict\").num_comments.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a3a0c05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verdict\n",
       "Asshole            505.537810\n",
       "Everyone Sucks     321.625571\n",
       "No A-holes here    172.189853\n",
       "Not enough info    283.547368\n",
       "Not the A-hole     685.821911\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.groupby(\"verdict\").score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c671069c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0120b3c3",
   "metadata": {},
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6de74de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_df.body.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4141682",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Not the A-hole', 'Everyone Sucks', 'Not the A-hole', ...,\n",
       "       'Asshole', 'Not the A-hole', 'Not the A-hole'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = clean_df.verdict.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c2045c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0712068c",
   "metadata": {},
   "source": [
    "**Tokenize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b2ee580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    urls = \"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
    "    detected_urls = re.findall(urls, text)\n",
    "    \n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "        \n",
    "    words = word_tokenize(text)\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    words = [x for x in words if x not in stop_words]\n",
    "    \n",
    "    clean_tokens = []\n",
    "    for word in words:\n",
    "        clean_token = lemmatizer.lemmatize(word).strip().lower()\n",
    "        clean_tokens.append(clean_token)\n",
    "        \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac03d138",
   "metadata": {},
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1bf14be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', DecisionTreeClassifier())\n",
    "    ])\n",
    "\n",
    "parameters = {\n",
    "        \"tfidf__use_idf\": [True, False],\n",
    "        \"clf__splitter\": [\"best\", \"random\"],\n",
    "        \"clf__min_samples_split\": [2, 10, 20]\n",
    "    }\n",
    "\n",
    "model = GridSearchCV(pipeline, parameters, verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "87046d18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5; 1/2] START clf__splitter=best..........................................\n",
      "[CV 1/5; 1/2] END ........................clf__splitter=best; total time= 1.9min\n",
      "[CV 2/5; 1/2] START clf__splitter=best..........................................\n",
      "[CV 2/5; 1/2] END ........................clf__splitter=best; total time= 1.7min\n",
      "[CV 3/5; 1/2] START clf__splitter=best..........................................\n",
      "[CV 3/5; 1/2] END ........................clf__splitter=best; total time= 1.9min\n",
      "[CV 4/5; 1/2] START clf__splitter=best..........................................\n",
      "[CV 4/5; 1/2] END ........................clf__splitter=best; total time= 1.9min\n",
      "[CV 5/5; 1/2] START clf__splitter=best..........................................\n",
      "[CV 5/5; 1/2] END ........................clf__splitter=best; total time= 1.8min\n",
      "[CV 1/5; 2/2] START clf__splitter=random........................................\n",
      "[CV 1/5; 2/2] END ......................clf__splitter=random; total time= 1.8min\n",
      "[CV 2/5; 2/2] START clf__splitter=random........................................\n",
      "[CV 2/5; 2/2] END ......................clf__splitter=random; total time= 1.7min\n",
      "[CV 3/5; 2/2] START clf__splitter=random........................................\n",
      "[CV 3/5; 2/2] END ......................clf__splitter=random; total time= 1.6min\n",
      "[CV 4/5; 2/2] START clf__splitter=random........................................\n",
      "[CV 4/5; 2/2] END ......................clf__splitter=random; total time= 1.7min\n",
      "[CV 5/5; 2/2] START clf__splitter=random........................................\n",
      "[CV 5/5; 2/2] END ......................clf__splitter=random; total time= 1.7min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('vect',\n",
       "                                        CountVectorizer(tokenizer=<function tokenize at 0x7f80688698b0>)),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf', DecisionTreeClassifier())]),\n",
       "             param_grid={'clf__splitter': ['best', 'random']}, verbose=10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5eb1ebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "978f5415",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        Asshole       0.18      0.15      0.16       619\n",
      " Everyone Sucks       0.10      0.08      0.09       170\n",
      "No A-holes here       0.08      0.06      0.07       249\n",
      "Not enough info       0.01      0.01      0.01       103\n",
      " Not the A-hole       0.75      0.80      0.77      3230\n",
      "\n",
      "       accuracy                           0.62      4371\n",
      "      macro avg       0.22      0.22      0.22      4371\n",
      "   weighted avg       0.59      0.62      0.60      4371\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "893e4f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3=\"I (29F) work in a tech company that delivers supermarket goods. I want to become Minister of Health in the future, so I'm working on a Data Science Nanodegree to learn more stuff, as well as working on my current job to get more experience. I have a project to deliver before April ends, and I've been struggling to finish it as I didn't pay much attention in my machine learning classes, so I asked a friend for help interpreting my results, and he absolutely refused to help me. I know I asked him at almost 11PM but that's what friends do, right? So Reddit, AITA?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3df8f977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I (29F) work in a tech company that delivers supermarket goods. I want to become Minister of Health in the future, so I'm working on a Data Science Nanodegree to learn more stuff, as well as working on my current job to get more experience. I have a project to deliver before April ends, and I've been struggling to finish it as I didn't pay much attention in my machine learning classes, so I asked a friend for help interpreting my results, and he absolutely refused to help me. I know I asked him at almost 11PM but that's what friends do, right? So Reddit, AITA?\n"
     ]
    }
   ],
   "source": [
    "print(test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1955e9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
